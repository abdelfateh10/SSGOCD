{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9115a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:25:59.435059Z",
     "iopub.status.busy": "2025-05-08T18:25:59.434357Z",
     "iopub.status.idle": "2025-05-08T18:26:04.399298Z",
     "shell.execute_reply": "2025-05-08T18:26:04.398282Z"
    },
    "papermill": {
     "duration": 4.970451,
     "end_time": "2025-05-08T18:26:04.401193",
     "exception": false,
     "start_time": "2025-05-08T18:25:59.430742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric==2.5.2\r\n",
      "  Downloading torch_geometric-2.5.2-py3-none-any.whl.metadata (64 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.5.2) (4.67.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.5.2) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.5.2) (1.15.2)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.5.2) (2025.3.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.5.2) (3.1.6)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.5.2) (3.11.16)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.5.2) (2.32.3)\r\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.5.2) (3.2.1)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.5.2) (1.2.2)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.5.2) (7.0.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.5.2) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.5.2) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.5.2) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.5.2) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.5.2) (6.2.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.5.2) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.5.2) (1.19.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric==2.5.2) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric==2.5.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric==2.5.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric==2.5.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric==2.5.2) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric==2.5.2) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric==2.5.2) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric==2.5.2) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric==2.5.2) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric==2.5.2) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric==2.5.2) (2025.1.31)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch_geometric==2.5.2) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch_geometric==2.5.2) (3.6.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric==2.5.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric==2.5.2) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric==2.5.2) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_geometric==2.5.2) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_geometric==2.5.2) (2024.2.0)\r\n",
      "Downloading torch_geometric-2.5.2-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\r\n",
      "Successfully installed torch_geometric-2.5.2\r\n"
     ]
    }
   ],
   "source": [
    "! pip install  torch_geometric==2.5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e586f9f",
   "metadata": {
    "papermill": {
     "duration": 0.004267,
     "end_time": "2025-05-08T18:26:04.410618",
     "exception": false,
     "start_time": "2025-05-08T18:26:04.406351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32402170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:26:04.419622Z",
     "iopub.status.busy": "2025-05-08T18:26:04.418891Z",
     "iopub.status.idle": "2025-05-08T18:26:15.850764Z",
     "shell.execute_reply": "2025-05-08T18:26:15.849907Z"
    },
    "papermill": {
     "duration": 11.437523,
     "end_time": "2025-05-08T18:26:15.852390",
     "exception": false,
     "start_time": "2025-05-08T18:26:04.414867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from sklearn.cluster import KMeans\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.metrics import f1_score as F1\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d313d",
   "metadata": {
    "papermill": {
     "duration": 0.002482,
     "end_time": "2025-05-08T18:26:15.857884",
     "exception": false,
     "start_time": "2025-05-08T18:26:15.855402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56f7cc46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:26:15.864350Z",
     "iopub.status.busy": "2025-05-08T18:26:15.863942Z",
     "iopub.status.idle": "2025-05-08T18:26:15.882608Z",
     "shell.execute_reply": "2025-05-08T18:26:15.882034Z"
    },
    "papermill": {
     "duration": 0.023327,
     "end_time": "2025-05-08T18:26:15.883713",
     "exception": false,
     "start_time": "2025-05-08T18:26:15.860386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "def relu(x: np.array):\n",
    "    x = (np.abs(x) + x) / 2.0\n",
    "    return x\n",
    "\n",
    "\n",
    "def ONMI(X, Y):\n",
    "    \"\"\"\n",
    "        Compute NMI between two overlapping community covers.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [N, m]\n",
    "            Matrix with samples stored as columns.\n",
    "        Y : array-like, shape [N, n]\n",
    "            Matrix with samples stored as columns.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        nmi : float\n",
    "            Float in [0, 1] quantifying the agreement between the two partitions.\n",
    "            Higher is better.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        McDaid, Aaron F., Derek Greene, and Neil Hurley.\n",
    "        \"Normalized mutual information to evaluate overlapping\n",
    "        community finding algorithms.\"\n",
    "        arXiv preprint arXiv:1110.2515 (2011).\n",
    "\n",
    "    \"\"\"\n",
    "    if not ((X == 0) | (X == 1)).all():\n",
    "        raise ValueError(\"X should be a binary matrix\")\n",
    "    if not ((Y == 0) | (Y == 1)).all():\n",
    "        raise ValueError(\"Y should be a binary matrix\")\n",
    "\n",
    "    if X.shape[1] > X.shape[0] or Y.shape[1] > Y.shape[0]:\n",
    "        warnings.warn(\"It seems that you forgot to transpose the F matrix\")\n",
    "    X = X.T\n",
    "    Y = Y.T\n",
    "\n",
    "    def cmp(x, y):\n",
    "        \"\"\"Compare two binary vectors.\"\"\"\n",
    "        a = (1 - x).dot(1 - y)\n",
    "        d = x.dot(y)\n",
    "        c = (1 - y).dot(x)\n",
    "        b = (1 - x).dot(y)\n",
    "        return a, b, c, d\n",
    "\n",
    "    def h(w, n):\n",
    "        \"\"\"Compute contribution of a single term to the entropy.\"\"\"\n",
    "        if w == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -w * np.log2(w / n)\n",
    "\n",
    "    def H(x, y):\n",
    "        \"\"\"Compute conditional entropy between two vectors.\"\"\"\n",
    "        a, b, c, d = cmp(x, y)\n",
    "        n = len(x)\n",
    "        if h(a, n) + h(d, n) >= h(b, n) + h(c, n):\n",
    "            return h(a, n) + h(b, n) + h(c, n) + h(d, n) - h(b + d, n) - h(a + c, n)\n",
    "        else:\n",
    "            return h(c + d, n) + h(a + b, n)\n",
    "\n",
    "    def H_uncond(X):\n",
    "        \"\"\"Compute unconditional entropy of a single binary matrix.\"\"\"\n",
    "        return sum(h(x.sum(), len(x)) + h(len(x) - x.sum(), len(x)) for x in X)\n",
    "\n",
    "    def H_cond(X, Y):\n",
    "        \"\"\"Compute conditional entropy between two binary matrices.\"\"\"\n",
    "        m, n = X.shape[0], Y.shape[0]\n",
    "        scores = np.zeros([m, n])\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                scores[i, j] = H(X[i], Y[j])\n",
    "        return scores.min(axis=1).sum()\n",
    "\n",
    "    if X.shape[1] != Y.shape[1]:\n",
    "        raise ValueError(\"Dimensions of X and Y don't match. (Samples must be stored as COLUMNS)\")\n",
    "    H_X = H_uncond(X)\n",
    "    H_Y = H_uncond(Y)\n",
    "    I_XY = 0.5 * (H_X + H_Y - H_cond(X, Y) - H_cond(Y, X))\n",
    "    return I_XY / max(H_X, H_Y)\n",
    "\n",
    "\n",
    "def find_best_thresh(label: np.array, z: np.array):\n",
    "    \"\"\"\n",
    "    寻找 overlapping_nmi最大时的阈值\n",
    "    :param label: 重叠社区标签， np.array  [N * K]\n",
    "    :param z: 社区表示矩阵， np.array  [N * K]\n",
    "    :return:\n",
    "\n",
    "    \"\"\"\n",
    "    thresh = 0.\n",
    "    best_thresh = 0.\n",
    "    max_onmi = 0.\n",
    "    while thresh <= np.max(z):\n",
    "        onmi_val = overlapping_nmi(label, z, thresh)\n",
    "        if onmi_val >= max_onmi:\n",
    "            best_thresh = thresh\n",
    "            max_onmi = onmi_val\n",
    "        thresh += 0.01\n",
    "    return best_thresh\n",
    "\n",
    "\n",
    "\n",
    "def overlapping_nmi(label: np.array, z: np.array, thresh=0.5):\n",
    "\n",
    "    z = relu(z)\n",
    "    pred = z > thresh\n",
    "    return ONMI(label, pred)\n",
    "\n",
    "\n",
    "def overlapping_f1_score(label: np.array, z: np.array, thresh=0.5):\n",
    "\n",
    "    pred = z > thresh\n",
    "    return F1(label, pred, average=\"micro\")\n",
    "\n",
    "def load_pyg_dataset(file_name, train_size, p_mis):\n",
    "    if not file_name.endswith('.npz'):\n",
    "        file_name += '.npz'\n",
    "    with np.load(file_name, allow_pickle=True) as loader:\n",
    "        loader = dict(loader)\n",
    "        A = sp.csr_matrix((loader['adj_matrix.data'], loader['adj_matrix.indices'],\n",
    "                           loader['adj_matrix.indptr']), shape=loader['adj_matrix.shape'])\n",
    "\n",
    "        if 'attr_matrix.data' in loader.keys():\n",
    "            X = sp.csr_matrix((loader['attr_matrix.data'], loader['attr_matrix.indices'],\n",
    "                               loader['attr_matrix.indptr']), shape=loader['attr_matrix.shape'])\n",
    "        else:\n",
    "            X = None\n",
    "\n",
    "        Z = sp.csr_matrix((loader['labels.data'], loader['labels.indices'],\n",
    "                           loader['labels.indptr']), shape=loader['labels.shape'])\n",
    "\n",
    "        # Remove self-loops\n",
    "        A = A.tolil()\n",
    "        A.setdiag(0)\n",
    "        A = A.tocsr()\n",
    "\n",
    "        # Convert label matrix to numpy\n",
    "        if sp.issparse(Z):\n",
    "            Z = Z.toarray().astype(np.float32)\n",
    "\n",
    "        # Convert data to PyTorch tensors\n",
    "        x = torch.tensor(X.toarray() if X is not None else [], dtype=torch.float)\n",
    "        edge_index = torch.tensor(A.nonzero(), dtype=torch.long)\n",
    "        y = torch.tensor(Z, dtype=torch.long)\n",
    "        num_classes = y.shape[1]\n",
    "        # print('num classes:', num_classes)\n",
    "        \n",
    "        num_nodes = x.shape[0]\n",
    "        num_train_nodes = int(train_size * num_nodes)\n",
    "\n",
    "        # Create a shuffled array of indices\n",
    "        indices = np.random.permutation(num_nodes)\n",
    "\n",
    "        # Create masks\n",
    "        train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "        # Assign indices to the training and test sets\n",
    "        train_mask[indices[:num_train_nodes]] = True\n",
    "        test_mask[indices[num_train_nodes:]] = True\n",
    "\n",
    "        # Feature swapping based on p_mis\n",
    "        if( p_mis>0.0):\n",
    "            # print(p_mis*100)\n",
    "            swap_count = int(num_nodes * p_mis / 2)\n",
    "            for _ in range(swap_count):\n",
    "                a = random.randint(0, num_nodes - 1)\n",
    "                b = random.randint(0, num_nodes - 1)\n",
    "                #print(a, ' ', b)\n",
    "                if a != b:\n",
    "                    x[[a, b], :] = x[[b, a], :]\n",
    "\n",
    "        # Create PyTorch Geometric Data object\n",
    "        data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask, test_mask=test_mask)\n",
    "        data.num_classes = num_classes\n",
    "        data.file_name = file_name\n",
    "        data.train_size = train_size\n",
    "\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf3839",
   "metadata": {
    "papermill": {
     "duration": 0.003514,
     "end_time": "2025-05-08T18:26:15.889829",
     "exception": false,
     "start_time": "2025-05-08T18:26:15.886315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Define The Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ef2811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:26:15.896403Z",
     "iopub.status.busy": "2025-05-08T18:26:15.895720Z",
     "iopub.status.idle": "2025-05-08T18:26:15.902351Z",
     "shell.execute_reply": "2025-05-08T18:26:15.901606Z"
    },
    "papermill": {
     "duration": 0.011098,
     "end_time": "2025-05-08T18:26:15.903551",
     "exception": false,
     "start_time": "2025-05-08T18:26:15.892453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim, latent_dim, num_heads, num_class):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.gat_layer = GATv2Conv(\n",
    "            in_channels=in_features,\n",
    "            out_channels=hidden_dim,\n",
    "            heads=num_heads,\n",
    "        )\n",
    "        self.batch_norm1 = nn.BatchNorm1d(hidden_dim * num_heads)\n",
    "        \n",
    "        self.gat_layer2 = GATv2Conv(\n",
    "            in_channels=hidden_dim * num_heads,\n",
    "            out_channels=latent_dim,\n",
    "            heads=num_heads,\n",
    "        )\n",
    "        self.batch_norm2 = nn.BatchNorm1d(latent_dim * num_heads)\n",
    "        \n",
    "        self.fc = nn.Linear(latent_dim * num_heads, num_class)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat_layer(x, edge_index)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        \n",
    "        x = self.gat_layer2(x, edge_index)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        m = F.normalize(x, p=2, dim=1)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        a_bar = torch.sigmoid(torch.matmul(m, m.t()))\n",
    "\n",
    "        return m, x, a_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efc07d4",
   "metadata": {
    "papermill": {
     "duration": 0.002349,
     "end_time": "2025-05-08T18:26:15.908477",
     "exception": false,
     "start_time": "2025-05-08T18:26:15.906128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a93c94e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:26:15.914766Z",
     "iopub.status.busy": "2025-05-08T18:26:15.914148Z",
     "iopub.status.idle": "2025-05-08T18:26:17.754962Z",
     "shell.execute_reply": "2025-05-08T18:26:17.754346Z"
    },
    "papermill": {
     "duration": 1.845292,
     "end_time": "2025-05-08T18:26:17.756344",
     "exception": false,
     "start_time": "2025-05-08T18:26:15.911052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[21957, 7793], edge_index=[2, 193500], y=[21957, 18], train_mask=[21957], test_mask=[21957], num_classes=18, file_name='/kaggle/input/overlappingdata/data/mag_cs.npz', train_size=0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/3093907754.py:154: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  edge_index = torch.tensor(A.nonzero(), dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "file_name = '/kaggle/input/overlappingdata/data/mag_cs.npz'\n",
    "dataset = load_pyg_dataset(file_name,train_size=0.1, p_mis=0.0) \n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ccb0f1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:26:17.762979Z",
     "iopub.status.busy": "2025-05-08T18:26:17.762717Z",
     "iopub.status.idle": "2025-05-08T18:26:17.775606Z",
     "shell.execute_reply": "2025-05-08T18:26:17.774886Z"
    },
    "papermill": {
     "duration": 0.017462,
     "end_time": "2025-05-08T18:26:17.776649",
     "exception": false,
     "start_time": "2025-05-08T18:26:17.759187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Semi-Supervised Graph Autoencoder for Overlapping Semantic Community Detection\n",
    "\n",
    "class SSGOCD(nn.Module):\n",
    "    def __init__(self, dataset, num_class, lr=5e-4, normalize_feature=True, lamda=0.5, alpha=1e-8, beta=1e-6, device='cpu'):\n",
    "        super(SSGOCD, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.num_class = num_class\n",
    "        self.lr = lr\n",
    "        self.normalize_feature = normalize_feature\n",
    "        self.lamda = lamda\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.device = device\n",
    "        \n",
    "        self.num_nodes = dataset.num_nodes\n",
    "        self.in_feat = dataset.num_features\n",
    "        self.n_hidden = 64\n",
    "        self.latent = 16\n",
    "        self.n_head = 8\n",
    "        \n",
    "        self.B = self.compute_B_matrix()\n",
    "        self.adj = self.compute_adj_matrix()\n",
    "        \n",
    "    def compute_B_matrix(self):\n",
    "        edge_index = self.dataset.edge_index.cpu().numpy()\n",
    "        num_nodes = self.dataset.num_nodes\n",
    "        A = coo_matrix((np.ones(edge_index.shape[1]), (edge_index[0], edge_index[1])), shape=(num_nodes, num_nodes))\n",
    "        A = torch.tensor(A.toarray(), dtype=torch.float).to(self.device)\n",
    "        \n",
    "        D = torch.diag(torch.sum(A, dim=1))\n",
    "        B = A - (1.0 / A.sum()) * torch.matmul(D, A)\n",
    "        return B\n",
    "\n",
    "    def compute_adj_matrix(self):\n",
    "        edge_index = self.dataset.edge_index.cpu().numpy()\n",
    "        num_nodes = self.dataset.num_nodes\n",
    "        A = coo_matrix((np.ones(edge_index.shape[1]), (edge_index[0], edge_index[1])), shape=(num_nodes, num_nodes))\n",
    "        A = torch.tensor(A.toarray(), dtype=torch.float).to(self.device)\n",
    "        return A\n",
    "\n",
    "    def l2_reg_loss(self, model, scale=1e-4):\n",
    "        loss = 0.0\n",
    "        for w in model.parameters():\n",
    "            loss += w.pow(2.).sum()\n",
    "        return loss * scale\n",
    "\n",
    "    def l1_reg_loss(self, model, scale=1e-4):\n",
    "        loss = 0.0\n",
    "        for w in model.parameters():\n",
    "            loss += w.abs().sum()\n",
    "        return loss * scale\n",
    "\n",
    "    def train(self, max_epoch=20, unsupervised=False, use_modularity=True):\n",
    "        self.to(self.device)\n",
    "        data = self.dataset.to(self.device)\n",
    "\n",
    "        if self.normalize_feature:\n",
    "            data.x = F.normalize(data.x)\n",
    "\n",
    "        encoder = Encoder(self.in_feat, self.n_hidden, self.latent, self.n_head, self.num_class).to(self.device)\n",
    "        optimizer = optim.AdamW(encoder.parameters(), lr=self.lr, weight_decay=5e-4)\n",
    "        \n",
    "        train_mask = data.train_mask\n",
    "        test_mask = data.test_mask\n",
    "        labels = data.y\n",
    "        \n",
    "        nmi_results = []\n",
    "        f1_score_results = []\n",
    "        \n",
    "        for epoch in range(1, max_epoch + 1):\n",
    "            encoder.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            m, z, A_bar = encoder(data.x, data.edge_index)\n",
    "            loss = F.mse_loss(A_bar, self.adj)\n",
    "\n",
    "            if not unsupervised:\n",
    "                loss += self.lamda * F.cross_entropy(z[train_mask], labels[train_mask].float())\n",
    "\n",
    "            if use_modularity:\n",
    "                modularity_loss = self.beta * torch.trace(m.t().matmul(self.B).matmul(m))\n",
    "                loss -= modularity_loss\n",
    "            \n",
    "            loss += self.l2_reg_loss(encoder, 1e-5)\n",
    "            loss += self.l1_reg_loss(encoder, 1e-6)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "               # self.eval()\n",
    "                thresh = 3.0 / self.num_class\n",
    "                nmi = overlapping_nmi(labels[test_mask].cpu().numpy(), z[test_mask].detach().cpu().numpy(), thresh)\n",
    "                f1_score = overlapping_f1_score(labels[test_mask].cpu().numpy(), z[test_mask].detach().cpu().numpy(), thresh)\n",
    "\n",
    "                nmi_results.append(nmi)\n",
    "                f1_score_results.append(f1_score)\n",
    "                \n",
    "                if epoch % 10 == 0:\n",
    "                    print(f'Epoch {epoch}, Loss: {loss.item():.4f}, NMI: {nmi:.4f}, F1 Score: {f1_score:.4f}')\n",
    "\n",
    "        print(f'Max Overlapping NMI: {np.max(nmi_results):.4f}')\n",
    "        print(f'Max Overlapping F1 Score: {np.max(f1_score_results):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99274ca",
   "metadata": {
    "papermill": {
     "duration": 0.0025,
     "end_time": "2025-05-08T18:26:17.781828",
     "exception": false,
     "start_time": "2025-05-08T18:26:17.779328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Initialize and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6cc7df8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:26:17.787799Z",
     "iopub.status.busy": "2025-05-08T18:26:17.787581Z",
     "iopub.status.idle": "2025-05-08T18:29:03.934997Z",
     "shell.execute_reply": "2025-05-08T18:29:03.934157Z"
    },
    "papermill": {
     "duration": 166.15198,
     "end_time": "2025-05-08T18:29:03.936439",
     "exception": false,
     "start_time": "2025-05-08T18:26:17.784459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2195)\n",
      "tensor(19762)\n",
      "Epoch 10, Loss: 1.8745, NMI: 0.4505, F1 Score: 0.7546\n",
      "Epoch 20, Loss: 1.7873, NMI: 0.5041, F1 Score: 0.7908\n",
      "Epoch 30, Loss: 1.7393, NMI: 0.5687, F1 Score: 0.8223\n",
      "Epoch 40, Loss: 1.7162, NMI: 0.5637, F1 Score: 0.8203\n",
      "Epoch 50, Loss: 1.7009, NMI: 0.5622, F1 Score: 0.8194\n",
      "Epoch 60, Loss: 1.6916, NMI: 0.5623, F1 Score: 0.8194\n",
      "Epoch 70, Loss: 1.6846, NMI: 0.5620, F1 Score: 0.8190\n",
      "Epoch 80, Loss: 1.6798, NMI: 0.5600, F1 Score: 0.8178\n",
      "Epoch 90, Loss: 1.6768, NMI: 0.5563, F1 Score: 0.8153\n",
      "Epoch 100, Loss: 1.6744, NMI: 0.5533, F1 Score: 0.8134\n",
      "Epoch 110, Loss: 1.6725, NMI: 0.5493, F1 Score: 0.8107\n",
      "Epoch 120, Loss: 1.6717, NMI: 0.5482, F1 Score: 0.8103\n",
      "Epoch 130, Loss: 1.6703, NMI: 0.5487, F1 Score: 0.8105\n",
      "Epoch 140, Loss: 1.6693, NMI: 0.5426, F1 Score: 0.8058\n",
      "Epoch 150, Loss: 1.6690, NMI: 0.5469, F1 Score: 0.8096\n",
      "Epoch 160, Loss: 1.6674, NMI: 0.5440, F1 Score: 0.8072\n",
      "Epoch 170, Loss: 1.6667, NMI: 0.5430, F1 Score: 0.8066\n",
      "Epoch 180, Loss: 1.6668, NMI: 0.5411, F1 Score: 0.8054\n",
      "Epoch 190, Loss: 1.6663, NMI: 0.5425, F1 Score: 0.8065\n",
      "Epoch 200, Loss: 1.6651, NMI: 0.5399, F1 Score: 0.8051\n",
      "Epoch 210, Loss: 1.6653, NMI: 0.5383, F1 Score: 0.8041\n",
      "Epoch 220, Loss: 1.6645, NMI: 0.5396, F1 Score: 0.8051\n",
      "Epoch 230, Loss: 1.6640, NMI: 0.5394, F1 Score: 0.8048\n",
      "Epoch 240, Loss: 1.6634, NMI: 0.5394, F1 Score: 0.8043\n",
      "Epoch 250, Loss: 1.6628, NMI: 0.5400, F1 Score: 0.8049\n",
      "Max Overlapping NMI: 0.5687\n",
      "Max Overlapping F1 Score: 0.8223\n"
     ]
    }
   ],
   "source": [
    "print(dataset.train_mask.sum())\n",
    "print(dataset.test_mask.sum())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SSGOCD(dataset, num_class=dataset.num_classes, lr=0.006, lamda=0.5, alpha=1e-5, beta=1e-6, device=device)\n",
    "model.train(max_epoch=250, unsupervised=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4548387,
     "sourceId": 7774097,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 191.277473,
   "end_time": "2025-05-08T18:29:06.756286",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-08T18:25:55.478813",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
